---
title: "biruoz2-sim-proj"
author: "Bryna Zhao"
date: "June 18, 2018"
output: html_document
---

# Simulation Study 1, Significance of Regression

## Introduction

In this simulation study we will investigate the significance of regression test. We will simulate from two different models:

The **"significant"** model

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}+ \beta_3 x_{i3} + \epsilon_i
\]

where $\epsilon_i \sim N(0, \sigma^2).$ and

- $\beta_0 = 3$
- $\beta_1 = 1$
- $\beta_2 = 1$
- $\beta_3 = 1$

The **"non-significant"** model

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}+ \beta_3 x_{i3} + \epsilon_i
\]

where $\epsilon_i \sim N(0, \sigma^2).$ and

- $\beta_0 = 3$
- $\beta_1 = 0$
- $\beta_2 = 0$
- $\beta_3 = 0$
For both, we will consider a sample size of 25 and three possible levels of noise. That is, three values of $\sigma$.
- n = 25
- $\sigma \in (1, 5, 10)$

For each model $\sigma$ combination use 2500 simulations. We will compare the true distribution and the empirical distribution from simulations. 

# Methods

- set the seed using my birthday
```{r}
birthday = 19870725
set.seed(birthday)
```


```{r}
n = 25
p = 4

# import study_1.csv to get x values
library(readr)
study_1 <- read_csv("study_1.csv")
# View(study_1)
x0 = rep(1, n)
x1 = study_1$x1
x2 = study_1$x2
x3 = study_1$x3
X = cbind(x0, x1, x2, x3)
C = solve(t(X) %*% X)

```


```{r}
# a simulation function taking sigma and beta values as arguments
sim_function = function(sigma, beta_0, beta_1, beta_2, beta_3){
  
num_sims = 2500
f_emp = rep(0, num_sims)
p_emp = rep(0, num_sims)
r_2_emp = rep(0, num_sims)


for(i in 1:num_sims) {
  eps = rnorm(n, mean = 0 , sd = sigma)
  study_1$y = beta_0 * x0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3 + eps
  fit = lm(y ~ x1 + x2 + x3, data = study_1)
  
  f_emp[i] = summary(fit)$fstatistic[1]
  p_emp[i] = pf(f_emp[i], df1 = summary(fit)$fstatistic[2], df2 = summary(fit)$fstatistic[3], lower.tail = FALSE)[[1]]
  r_2_emp[i] = summary(fit)$r.squared 
  }  

  return(cbind(f_emp, p_emp, r_2_emp))
  
}

```


- **Significant $\sigma = 1$**
```{r}
# true values

sigma = 1
beta_0 = 3
beta_1 = 1 
beta_2 = 1
beta_3 = 1
beta = c(beta_0, beta_1, beta_2, beta_3)

f = (sigma ^ 2 + X %*% beta ) / sigma ^ 2
diff = (max(f) - min(f)) / length(f)
x = seq(min(f), max(f), diff)

# empirical values
result = sim_function(sigma = 1, beta_0 = 3, beta_1 = 1, beta_2 = 1, beta_3 = 1)
f_e_s1 = result[, 1]
p_e_s1 = result[, 2]
r_2_e_s1 = result[, 3]


```

```{r}

hist(f_e_s1, prob = TRUE, breaks = 100, xlab = "F statistic", ylim = c(0, 0.4), 
     xlim = c(0, 100),  main = "Sigma = 1 Significant", border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)
hist(p_e_s1, prob = TRUE, breaks = 100, xlab = "P_value", main = "Sigma = 1 Significant",
     border = "red")
hist(r_2_e_s1, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 1 Significant", 
     border = "magenta")
```


- **Non-significant $\sigma = 1$**
```{r}
# true values

sigma = 1
beta_0 = 3
beta_1 = 0 
beta_2 = 0
beta_3 = 0
beta = c(beta_0, beta_1, beta_2, beta_3)

f = (sigma ^ 2 + X %*% beta ) / sigma ^ 2
diff = (max(f) - min(f)) / length(f)
x = seq(min(f), max(f), diff)

# empirical values
result = sim_function(sigma = 1, beta_0 = 3, beta_1 = 0, beta_2 = 0, beta_3 = 0)
f_e_n1 = result[, 1]
p_e_n1 = result[, 2]
r_2_e_n1 = result[,3]

```

```{r}

hist(f_e_n1, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 1 Non-significant", 
     border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)
hist(p_e_n1, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 1 Non-significant",
     border = "red")
hist(r_2_e_n1, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 1 Non-significant",
     border = "magenta")

```


- **Significant $\sigma = 5$**
```{r}
# true values

sigma = 5
beta_0 = 3
beta_1 = 1 
beta_2 = 1
beta_3 = 1
beta = c(beta_0, beta_1, beta_2, beta_3)

f = (sigma ^ 2 + X %*% beta ) / sigma ^ 2
diff = (max(f) - min(f)) / length(f)
x = seq(min(f), max(f), diff)

# empirical values
result = sim_function(sigma = 1, beta_0 = 3, beta_1 = 1, beta_2 = 1, beta_3 = 1)
f_e_s5 = result[, 1]
p_e_s5 = result[, 2]
r_2_e_s5 = result[,3]


```

```{r}
hist(f_e_s5, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 5 Significant",
     ylim = c(0, 0.4), xlim = c(0, 100), border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)
hist(p_e_s5, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 5 Significant", 
     border = "red")
hist(r_2_e_s5, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 5 Significant", 
     border = "magenta")

```


- **Non-significant $\sigma = 5$**
```{r}
# true values

sigma = 5
beta_0 = 3
beta_1 = 0 
beta_2 = 0
beta_3 = 0
beta = c(beta_0, beta_1, beta_2, beta_3)

f = (sigma ^ 2 + X %*% beta ) / sigma ^ 2
diff = (max(f) - min(f)) / length(f)
x = seq(min(f), max(f), diff)

# empirical values
result = sim_function(sigma = 1, beta_0 = 3, beta_1 = 0, beta_2 = 0, beta_3 = 0)
f_e_n5 = result[, 1]
p_e_n5 = result[, 2]
r_2_e_n5 = result[,3]

```

```{r}

hist(f_e_n5, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 5 Non-significant",
     border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)
hist(p_e_n5, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 5 Non-significant",
     border = "red")
hist(r_2_e_n5, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 5 Non-significant", 
     border = "magenta")

```


- **Significant $\sigma = 10$**
```{r}
# true values

sigma = 10
beta_0 = 3
beta_1 = 1 
beta_2 = 1
beta_3 = 1
beta = c(beta_0, beta_1, beta_2, beta_3)

f = (sigma ^ 2 + X %*% beta ) / sigma ^ 2
diff = (max(f) - min(f)) / length(f)
x = seq(min(f), max(f), diff)

# empirical values
result = sim_function(sigma = 1, beta_0 = 3, beta_1 = 1, beta_2 = 1, beta_3 = 1)
f_e_s10 = result[, 1]
p_e_s10 = result[, 2]
r_2_e_s10 = result[,3]


```

```{r}
hist(f_e_s10, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 10 Significant", 
     ylim = c(0, 0.4), xlim = c(0, 100),  border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)
hist(p_e_s10, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 10 Significant", 
     border = "red")
hist(r_2_e_s10, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 10 Significant", 
     border = "magenta")

```


- **Non-significant $\sigma = 10$**
```{r}
# true values

sigma = 10
beta_0 = 3
beta_1 = 0 
beta_2 = 0
beta_3 = 0
beta = c(beta_0, beta_1, beta_2, beta_3)

f = (sigma ^ 2 + X %*% beta ) / sigma ^ 2
diff = (max(f) - min(f)) / length(f)
x = seq(min(f), max(f), diff)

# empirical values
result = sim_function(sigma = 1, beta_0 = 3, beta_1 = 0, beta_2 = 0, beta_3 = 0)
f_e_n10 = result[, 1]
p_e_n10 = result[, 2]
r_2_e_n10 = result[,3]

```

```{r}

hist(f_e_n10, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 10 Non-significant", 
     border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)
hist(p_e_n10, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 10 Non-significant", 
     border = "red")
hist(r_2_e_n10, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 10 Non-significant",  
     border = "magenta")

```

## Result

- Organize the plots in a grid for easy comparison

**Significant Models**
```{r}
par(mfrow=c(1,3))
# F statistic
hist(f_e_s1, prob = TRUE, breaks = 100, xlab = "F statistic", ylim = c(0, 0.4), 
     xlim = c(0, 100),  main = "Sigma = 1 Significant", border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)

hist(f_e_s5, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 5 Significant",
     ylim = c(0, 0.4), xlim = c(0, 100), border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)

hist(f_e_s10, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 10 Significant", 
     ylim = c(0, 0.4), xlim = c(0, 100),  border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)

# P value
hist(p_e_s1, prob = TRUE, breaks = 100, xlab = "P_value", main = "Sigma = 1 Significant",
     border = "red", xlim = c(0, 0.00001))

hist(p_e_s5, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 5 Significant", 
     border = "red", xlim = c(0, 0.00001))

hist(p_e_s10, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 10 Significant", 
     border = "red", xlim = c(0, 0.00001))

# R2
hist(r_2_e_s1, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 1 Significant", 
     border = "magenta")


hist(r_2_e_s5, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 5 Significant", 
     border = "magenta")

hist(r_2_e_s10, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 10 Significant", 
     border = "magenta")

```

**Non-significant Models**

```{r}
par(mfrow=c(1,3))
# F statistic
hist(f_e_n1, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 1 Non-significant", 
     border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)

hist(f_e_n5, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 5 Non-significant",
     border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)

hist(f_e_n10, prob = TRUE, breaks = 100, xlab = "F statistic", main = "Sigma = 10 Non-significant", 
     border = "dodgerblue")
curve(df(x, df1 = p - 1, df2 = n - p), col = "darkorange", add = TRUE, lwd = 3)


# P value
hist(p_e_n1, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 1 Non-significant",
     border = "red")
hist(p_e_n5, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 5 Non-significant",
     border = "red")

hist(p_e_n10, prob = TRUE, breaks = 100, xlab = "P value", main = "Sigma = 10 Non-significant", 
     border = "red")

# R2

hist(r_2_e_n1, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 1 Non-significant", ylim = c(0, 11),
     border = "magenta")

hist(r_2_e_n5, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 5 Non-significant", 
     border = "magenta")

hist(r_2_e_n10, prob = TRUE, breaks = 100, xlab = "R2", main = "Sigma = 10 Non-significant",  
     border = "magenta")



```




## Discussion

- Do we know the true distribution of any of these values?

True F statistics follow F distributions with degrees of freedom p-1 and n-p.

- How do the empirical distributions from the simulations compare to the true distributions? (You could consider adding a curve for the true distributions if you know them.)

Under the null hypothesis, empirical distributions of F statistics match the true distibutions.

- How are R2 and $\sigma$ related? Is the relationship the same for the significant and non-significant models?

R2 or the coefficient of determination is 1 - SSE / SST, is the proportion of observed variation in y that can be explained by the simple linear regression model. When the noise increases, the proportion that can be explained will decrease which means R2 will decrease. The effect is stronger on non-significant models.



# Simulation Study 2, Using RMSE for Selection?

## Introduction

In this simulation study we will from the model:


\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}+ \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5}+ \beta_6 x_{i6} + \epsilon_i
\]

where $\epsilon_i \sim N(0, \sigma^2).$ and

- $\beta_0 = 0$
- $\beta_1 = 5$
- $\beta_2 = -4$
- $\beta_3 = 1.6$
- $\beta_4 = -1.1$
- $\beta_5 = 0.7$
- $\beta_6 = 0.3$

And we will consider a sample size of 500 and three possible levels of noise. That is, three values of $\sigma$.
- $ n = 500$
- $\sigma \in (1, 2, 4)$

Each time you simulate the data, randomly split the data into train and test sets of equal sizes (250 observations for training, 250 observations for testing).

For each, fit nine models, with forms:

- y ~ x1
- y ~ x1 + x2
- y ~ x1 + x2 + x3
- y ~ x1 + x2 + x3 + x4
- y ~ x1 + x2 + x3 + x4 + x5, the correct form of the model
- y ~ x1 + x2 + x3 + x4 + x5 + x6
- y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7
- y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8
- y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9


## Methods

```{r}
birthday = 19870725
set.seed(birthday)
```

```{r}
library(readr)
study_2 <- read_csv("study_2.csv")
# View(study_2)
x1 = study_2$x1
x2 = study_2$x2
x3 = study_2$x3
x4 = study_2$x4
x5 = study_2$x5
x6 = study_2$x6
x7 = study_2$x7
x8 = study_2$x8
x9 = study_2$x9

n = 500
beta_0 = 0
beta_1 = 5
beta_2 = -4
beta_3 = 1.6
beta_4 = -1.1
beta_5 = 0.7
beta_6 = 0.3

num_sims = 1000
```
- $\sigma = 1$
```{r}
sigma = 1
```


```{r}


rmse_11_trn = rep(0, num_sims)
rmse_11_tst = rep(0, num_sims)
rmse_12_trn = rep(0, num_sims)
rmse_12_tst = rep(0, num_sims)
rmse_13_trn = rep(0, num_sims)
rmse_13_tst = rep(0, num_sims)
rmse_14_trn = rep(0, num_sims)
rmse_14_tst = rep(0, num_sims)
rmse_15_trn = rep(0, num_sims)
rmse_15_tst = rep(0, num_sims)
rmse_16_trn = rep(0, num_sims)
rmse_16_tst = rep(0, num_sims)
rmse_17_trn = rep(0, num_sims)
rmse_17_tst = rep(0, num_sims)
rmse_18_trn = rep(0, num_sims)
rmse_18_tst = rep(0, num_sims)
rmse_19_trn = rep(0, num_sims)
rmse_19_tst = rep(0, num_sims)

for (i in 1:num_sims){
  eps = rnorm(n, mean = 0, sd = sigma)
  study_2$y = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3 + beta_4 * x4 + beta_5 * x5 + beta_6 * x6 + eps
  # split into train and test
  trn_index = sample(1:n, 250)
  train = study_2[trn_index, ]
  test = study_2[-trn_index, ]
  fit_11_trn = lm(y ~ x1, data = train)
  rmse_11_trn[i] = sqrt(mean(fit_11_trn$residuals ^ 2))
  rmse_11_tst[i] = sqrt(mean((test$y - predict(fit_11_trn, newdata = test)) ^ 2))
  fit_12_trn = lm(y ~ x1 + x2, data = train)
  rmse_12_trn[i] = sqrt(mean(fit_12_trn$residuals ^ 2))
  rmse_12_tst[i] = sqrt(mean((test$y - predict(fit_12_trn, newdata = test)) ^ 2)) 
  fit_13_trn = lm(y ~ x1 + x2 + x3, data = train)
  rmse_13_trn[i] = sqrt(mean(fit_13_trn$residuals ^ 2))
  rmse_13_tst[i] = sqrt(mean((test$y - predict(fit_13_trn, newdata = test)) ^ 2))   
  fit_14_trn = lm(y ~ x1 + x2 + x3 + x4, data = train)
  rmse_14_trn[i] = sqrt(mean(fit_14_trn$residuals ^ 2))
  rmse_14_tst[i] = sqrt(mean((test$y - predict(fit_14_trn, newdata = test)) ^ 2))  
  fit_15_trn = lm(y ~ x1 + x2 + x3 + x4 + x5, data = train)
  rmse_15_trn[i] = sqrt(mean(fit_15_trn$residuals ^ 2))
  rmse_15_tst[i] = sqrt(mean((test$y - predict(fit_15_trn, newdata = test)) ^ 2)) 
  fit_16_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train)
  rmse_16_trn[i] = sqrt(mean(fit_16_trn$residuals ^ 2))
  rmse_16_tst[i] = sqrt(mean((test$y - predict(fit_16_trn, newdata = test)) ^ 2)) 
  fit_17_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = train)
  rmse_17_trn[i] = sqrt(mean(fit_17_trn$residuals ^ 2))
  rmse_17_tst[i] = sqrt(mean((test$y - predict(fit_17_trn, newdata = test)) ^ 2))
  fit_18_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = train)
  rmse_18_trn[i] = sqrt(mean(fit_18_trn$residuals ^ 2))
  rmse_18_tst[i] = sqrt(mean((test$y - predict(fit_18_trn, newdata = test)) ^ 2))
  fit_19_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, data = train)
  rmse_19_trn[i] = sqrt(mean(fit_19_trn$residuals ^ 2))
  rmse_19_tst[i] = sqrt(mean((test$y - predict(fit_19_trn, newdata = test)) ^ 2)) 
  
}

mean11trn = mean(rmse_11_trn)
mean11tst = mean(rmse_11_tst)
mean12trn = mean(rmse_12_trn)
mean12tst = mean(rmse_12_tst)
mean13trn = mean(rmse_13_trn)
mean13tst = mean(rmse_13_tst)
mean14trn = mean(rmse_14_trn)
mean14tst = mean(rmse_14_tst)
mean15trn = mean(rmse_15_trn)
mean15tst = mean(rmse_15_tst)
mean16trn = mean(rmse_16_trn)
mean16tst = mean(rmse_16_tst)
mean17trn = mean(rmse_17_trn)
mean17tst = mean(rmse_17_tst)
mean18trn = mean(rmse_18_trn)
mean18tst = mean(rmse_18_tst)
mean19trn = mean(rmse_19_trn)
mean19tst = mean(rmse_19_tst)

```


- $\sigma = 2$
```{r}
sigma = 2
```


```{r}
rmse_21_trn = rep(0, num_sims)
rmse_21_tst = rep(0, num_sims)
rmse_22_trn = rep(0, num_sims)
rmse_22_tst = rep(0, num_sims)
rmse_23_trn = rep(0, num_sims)
rmse_23_tst = rep(0, num_sims)
rmse_24_trn = rep(0, num_sims)
rmse_24_tst = rep(0, num_sims)
rmse_25_trn = rep(0, num_sims)
rmse_25_tst = rep(0, num_sims)
rmse_26_trn = rep(0, num_sims)
rmse_26_tst = rep(0, num_sims)
rmse_27_trn = rep(0, num_sims)
rmse_27_tst = rep(0, num_sims)
rmse_28_trn = rep(0, num_sims)
rmse_28_tst = rep(0, num_sims)
rmse_29_trn = rep(0, num_sims)
rmse_29_tst = rep(0, num_sims)

for (i in 1:num_sims){
  eps = rnorm(n, mean = 0, sd = sigma)
  study_2$y = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3 + beta_4 * x4 + beta_5 * x5 + beta_6 * x6 + eps
  # split into train and test
  trn_index = sample(1:n, 250)
  train = study_2[trn_index, ]
  test = study_2[-trn_index, ]
  fit_21_trn = lm(y ~ x1, data = train)
  rmse_21_trn[i] = sqrt(mean(fit_21_trn$residuals ^ 2))
  rmse_21_tst[i] = sqrt(mean((test$y - predict(fit_21_trn, newdata = test)) ^ 2))
  fit_22_trn = lm(y ~ x1 + x2, data = train)
  rmse_22_trn[i] = sqrt(mean(fit_22_trn$residuals ^ 2))
  rmse_22_tst[i] = sqrt(mean((test$y - predict(fit_22_trn, newdata = test)) ^ 2)) 
  fit_23_trn = lm(y ~ x1 + x2 + x3, data = train)
  rmse_23_trn[i] = sqrt(mean(fit_23_trn$residuals ^ 2))
  rmse_23_tst[i] = sqrt(mean((test$y - predict(fit_23_trn, newdata = test)) ^ 2))   
  fit_24_trn = lm(y ~ x1 + x2 + x3 + x4, data = train)
  rmse_24_trn[i] = sqrt(mean(fit_24_trn$residuals ^ 2))
  rmse_24_tst[i] = sqrt(mean((test$y - predict(fit_24_trn, newdata = test)) ^ 2))  
  fit_25_trn = lm(y ~ x1 + x2 + x3 + x4 + x5, data = train)
  rmse_25_trn[i] = sqrt(mean(fit_25_trn$residuals ^ 2))
  rmse_25_tst[i] = sqrt(mean((test$y - predict(fit_25_trn, newdata = test)) ^ 2)) 
  fit_26_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train)
  rmse_26_trn[i] = sqrt(mean(fit_26_trn$residuals ^ 2))
  rmse_26_tst[i] = sqrt(mean((test$y - predict(fit_26_trn, newdata = test)) ^ 2)) 
  fit_27_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = train)
  rmse_27_trn[i] = sqrt(mean(fit_27_trn$residuals ^ 2))
  rmse_27_tst[i] = sqrt(mean((test$y - predict(fit_27_trn, newdata = test)) ^ 2))
  fit_28_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = train)
  rmse_28_trn[i] = sqrt(mean(fit_28_trn$residuals ^ 2))
  rmse_28_tst[i] = sqrt(mean((test$y - predict(fit_28_trn, newdata = test)) ^ 2))
  fit_29_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, data = train)
  rmse_29_trn[i] = sqrt(mean(fit_29_trn$residuals ^ 2))
  rmse_29_tst[i] = sqrt(mean((test$y - predict(fit_29_trn, newdata = test)) ^ 2)) 
  
}

mean21trn = mean(rmse_21_trn)
mean21tst = mean(rmse_21_tst)
mean22trn = mean(rmse_22_trn)
mean22tst = mean(rmse_22_tst)
mean23trn = mean(rmse_23_trn)
mean23tst = mean(rmse_23_tst)
mean24trn = mean(rmse_24_trn)
mean24tst = mean(rmse_24_tst)
mean25trn = mean(rmse_25_trn)
mean25tst = mean(rmse_25_tst)
mean26trn = mean(rmse_26_trn)
mean26tst = mean(rmse_26_tst)
mean27trn = mean(rmse_27_trn)
mean27tst = mean(rmse_27_tst)
mean28trn = mean(rmse_28_trn)
mean28tst = mean(rmse_28_tst)
mean29trn = mean(rmse_29_trn)
mean29tst = mean(rmse_29_tst)

```


- $\sigma = 4$
```{r}
sigma = 4
```


```{r}
rmse_41_trn = rep(0, num_sims)
rmse_41_tst = rep(0, num_sims)
rmse_42_trn = rep(0, num_sims)
rmse_42_tst = rep(0, num_sims)
rmse_43_trn = rep(0, num_sims)
rmse_43_tst = rep(0, num_sims)
rmse_44_trn = rep(0, num_sims)
rmse_44_tst = rep(0, num_sims)
rmse_45_trn = rep(0, num_sims)
rmse_45_tst = rep(0, num_sims)
rmse_46_trn = rep(0, num_sims)
rmse_46_tst = rep(0, num_sims)
rmse_47_trn = rep(0, num_sims)
rmse_47_tst = rep(0, num_sims)
rmse_48_trn = rep(0, num_sims)
rmse_48_tst = rep(0, num_sims)
rmse_49_trn = rep(0, num_sims)
rmse_49_tst = rep(0, num_sims)

for (i in 1:num_sims){
  eps = rnorm(n, mean = 0, sd = sigma)
  study_2$y = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3 + beta_4 * x4 + beta_5 * x5 + beta_6 * x6 + eps
  # split into train and test
  trn_index = sample(1:n, 250)
  train = study_2[trn_index, ]
  test = study_2[-trn_index, ]
  fit_41_trn = lm(y ~ x1, data = train)
  rmse_41_trn[i] = sqrt(mean(fit_41_trn$residuals ^ 2))
  rmse_41_tst[i] = sqrt(mean((test$y - predict(fit_41_trn, newdata = test)) ^ 2))
  
  fit_42_trn = lm(y ~ x1 + x2, data = train)
  rmse_42_trn[i] = sqrt(mean(fit_42_trn$residuals ^ 2))
  rmse_42_tst[i] = sqrt(mean((test$y - predict(fit_42_trn, newdata = test)) ^ 2)) 
  fit_43_trn = lm(y ~ x1 + x2 + x3, data = train)
  rmse_43_trn[i] = sqrt(mean(fit_43_trn$residuals ^ 2))
  rmse_43_tst[i] = sqrt(mean((test$y - predict(fit_43_trn, newdata = test)) ^ 2))   
  fit_44_trn = lm(y ~ x1 + x2 + x3 + x4, data = train)
  rmse_44_trn[i] = sqrt(mean(fit_44_trn$residuals ^ 2))
  rmse_44_tst[i] = sqrt(mean((test$y - predict(fit_44_trn, newdata = test)) ^ 2))  
  fit_45_trn = lm(y ~ x1 + x2 + x3 + x4 + x5, data = train)
  rmse_45_trn[i] = sqrt(mean(fit_45_trn$residuals ^ 2))
  rmse_45_tst[i] = sqrt(mean((test$y - predict(fit_45_trn, newdata = test)) ^ 2)) 
  fit_46_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train)
  rmse_46_trn[i] = sqrt(mean(fit_46_trn$residuals ^ 2))
  rmse_46_tst[i] = sqrt(mean((test$y - predict(fit_46_trn, newdata = test)) ^ 2)) 
  fit_47_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = train)
  rmse_47_trn[i] = sqrt(mean(fit_47_trn$residuals ^ 2))
  rmse_47_tst[i] = sqrt(mean((test$y - predict(fit_47_trn, newdata = test)) ^ 2))
  fit_48_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = train)
  rmse_48_trn[i] = sqrt(mean(fit_48_trn$residuals ^ 2))
  rmse_48_tst[i] = sqrt(mean((test$y - predict(fit_48_trn, newdata = test)) ^ 2))
  fit_49_trn = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, data = train)
  rmse_49_trn[i] = sqrt(mean(fit_49_trn$residuals ^ 2))
  rmse_49_tst[i] = sqrt(mean((test$y - predict(fit_49_trn, newdata = test)) ^ 2)) 
  
}

mean41trn = mean(rmse_41_trn)
mean41tst = mean(rmse_41_tst)
mean42trn = mean(rmse_42_trn)
mean42tst = mean(rmse_42_tst)
mean43trn = mean(rmse_43_trn)
mean43tst = mean(rmse_43_tst)
mean44trn = mean(rmse_44_trn)
mean44tst = mean(rmse_44_tst)
mean45trn = mean(rmse_45_trn)
mean45tst = mean(rmse_45_tst)
mean46trn = mean(rmse_46_trn)
mean46tst = mean(rmse_46_tst)
mean47trn = mean(rmse_47_trn)
mean47tst = mean(rmse_47_tst)
mean48trn = mean(rmse_48_trn)
mean48tst = mean(rmse_48_tst)
mean49trn = mean(rmse_49_trn)
mean49tst = mean(rmse_49_tst)

```



## Results

**Create plots that show how average Train RMSE and average Test RMSE change as a function of model size**
- $\sigma = 1$
```{r}
# prepare for plotting
mean1trn = c(mean11trn, mean12trn, mean13trn, mean14trn, mean15trn, mean16trn, mean17trn, mean18trn, mean19trn)
mean1tst = c(mean11tst, mean12tst, mean13tst, mean14tst, mean15tst, mean16tst, mean17tst, mean18tst, mean19tst)

model_size = seq(1, 9, 1)

par(mfrow=c(1,2))
rmse_train1 = data.frame(mean1trn, model_size)

rmse_test1 = data.frame(mean1tst, model_size)

plot(mean1trn ~ model_size , data = rmse_train1, type = "o", cex  = 1, lwd = 2, 
     xlab = "Average Train RMSE and Test RMSE", ylab = "Model Size",
     main = "RMSE vs. Model Size(sigma = 1)", col = "dodgerblue")
lines(rmse_test1$model_size, rmse_test1$mean1tst, col="darkorange", lty = 2, lwd = 2)
legend("topright", c("Train", "Test"), lty = c(1, 2), lwd = 2,
       col = c("dodgerblue", "darkorange"))

```

- $\sigma = 2$
```{r}
mean2trn = c(mean21trn, mean22trn, mean23trn, mean24trn, mean25trn, mean26trn, mean27trn, mean28trn, mean29trn)
mean2tst = c(mean21tst, mean22tst, mean23tst, mean24tst, mean25tst, mean26tst, mean27tst, mean28tst, mean29tst)


par(mfrow=c(1,2))
rmse_train2 = data.frame(mean2trn, model_size)
rmse_test2 = data.frame(mean2tst, model_size)

plot(mean2trn ~ model_size, data = rmse_train2, type = "o", cex  = 1, lwd = 2, 
     xlab = "Average Train RMSE and Test RMSE", ylab = "Model Size",
     main = "RMSE vs. Model Size(sigma = 2)", 
     col = "dodgerblue")
lines(rmse_test2$model_size, rmse_test2$mean2tst, col="darkorange", lty = 2, lwd = 2)
legend("topright", c("Train", "Test"), lty = c(1, 2), lwd = 2,
       col = c("dodgerblue", "darkorange"))


```


- $\sigma = 4$
```{r}
mean4trn = c(mean41trn, mean42trn, mean43trn, mean44trn, mean45trn, mean46trn, mean47trn, mean48trn, mean49trn)
mean4tst = c(mean41tst, mean42tst, mean43tst, mean44tst, mean45tst, mean46tst, mean47tst, mean48tst, mean49tst)


par(mfrow=c(1,2))
rmse_train4 = data.frame(mean4trn, model_size)
rmse_test4 = data.frame(mean4tst, model_size)

plot(mean4trn ~ model_size, data = rmse_train4, type = "o", cex  = 1, lwd = 2, 
     xlab = "Average Train RMSE and Test RMSE", ylab = "Model Size",
     main = "RMSE vs. Model Size(sigma = 4)", 
     col = "dodgerblue")
lines(rmse_test4$model_size, rmse_test4$mean4tst, col="darkorange", lty = 2, lwd = 2)
legend("topright", c("Train", "Test"), lty = c(1, 2), lwd = 2,
       col = c("dodgerblue", "darkorange"))

```




**Show the number of times the model of each size was chosen for each value of 
$\sigma$.**



```{r}
# sigma = 1


model_compare1 = data.frame(rmse_11_tst, rmse_12_tst, rmse_13_tst, rmse_14_tst, rmse_15_tst, rmse_16_tst, rmse_17_tst, rmse_18_tst, rmse_19_tst)

chosen_1 = rep(0, num_sims)
boundaries = seq(0, 9, 1)

for (i in 1: nrow(model_compare1)){
  chosen_1[i] = which.min(model_compare1[i, ])
}

hist(chosen_1, freq = TRUE, breaks = boundaries, xlab = "Model Size From 1 to 9", ylab = "Count", labels = TRUE,
     main = "Count of Chosen Model (sigma = 1)", ylim = c(0, 600), col = "darkorange", las = 1)

# sigma = 2
model_compare2 = data.frame(rmse_21_tst, rmse_22_tst, rmse_23_tst, rmse_24_tst, rmse_25_tst, rmse_26_tst, rmse_27_tst, rmse_28_tst, rmse_29_tst)

chosen_2 = rep(0, num_sims)

for (i in 1: nrow(model_compare2)){
  chosen_2[i] = which.min(model_compare2[i, ])
}


hist(chosen_2, freq = TRUE, breaks = boundaries, xlab = "Model Size From 1 to 9", ylab = "Count", labels = TRUE, main = "Count of Chosen Model (sigma = 2)", xlim = c(0, 9), ylim = c(0, 600), col = "darkorange", las = 1)

# sigma = 4
model_compare4 = data.frame(rmse_41_tst, rmse_42_tst, rmse_43_tst, rmse_44_tst, rmse_45_tst, rmse_46_tst, rmse_47_tst, rmse_48_tst, rmse_49_tst)

chosen_4 = rep(0, num_sims)

for (i in 1: nrow(model_compare4)){
  chosen_4[i] = which.min(model_compare4[i, ])
}


hist(chosen_4, freq = TRUE, breaks = boundaries, xlab = "Model Size From 1 to 9", ylab = "Count", labels = TRUE, main = "Count of Chosen Model (sigma = 4)", ylim = c(0, 600), col = "darkorange")



```


##Discussion

- How average Train RMSE and average Test RMSE change as a function of model size?

For train RMSE, the overral trend is when model size increases the mean of Train RMSE decreases, model 9 has the smallest train RMSE, as expected. For test RMSE, when $\sigma$ = 1 or 2, model 6 has got the smallest test RMSE; when noise increase ($\sigma$ = 4), model 3 has the smallest test RMSE. 

- How times the model of each size was chosen for each value of $\sigma$ ?

**sigma = 1**
1. model 1 was chosen for 0 time;
2. model 2 was chosen for 0 time;
3. model 3 was chosen for 0 time;
4. model 4 was chosen for 5 times;
5. model 5 was chosen for 23 times;
6. model 6 was chosen for 528 times;
7. model 7 was chosen for 208 times;
8. model 8 was chosen for 136 times;
9. model 9 was chosen for 100 times;

**sigma = 2**
1. model 1 was chosen for 0 time;
2. model 2 was chosen for 0 time;
3. model 3 was chosen for 47 times;
4. model 4 was chosen for 80 times;
5. model 5 was chosen for 86 times;
6. model 6 was chosen for 430 times;
7. model 7 was chosen for 143 times;
8. model 8 was chosen for 99 times;
9. model 9 was chosen for 115 times;

**sigma = 4**
1. model 1 was chosen for 0 time;
2. model 2 was chosen for 12 times;
3. model 3 was chosen for 127 times;
4. model 4 was chosen for 198 times;
5. model 5 was chosen for 112 times;
6. model 6 was chosen for 240 times;
7. model 7 was chosen for 94 times;
8. model 8 was chosen for 55 times;
9. model 9 was chosen for 72 times;

- Does the method always select the correct model? On average, does it select the correct model?
When $\sigma$ = 1, the possibility of choosing model 6 is larger than 50%.
When $\sigma$ = 2, the possibility of choosing model 6 is larger than 40%.
When $\sigma$ = 4, the possibility of choosing each model is more equally distributed. 
In each case, the chance of choosing the correct model (model 5) is smaller than 20%. On average, it's not very likely to select the correct model.

- How does the level of noise affect the results?

When the level of noise increases,  the chance of each model being chosen increases and it's harder to find a constant model.


# Simulation Study 3, Power

## Introduction

In this simulation study we will from the model:

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \epsilon_i
\]

where $\epsilon_i \sim N(0, \sigma^2).$ and

- $\beta_1 \in (-2, -1.9, ..., 1.9, 2)$

- $\sigma \in (1, 2, 4)$

- $n \in (10, 20, 30) $

\[
\hat{\text{Power}} = \hat{P}[\text{Reject } H_0 \mid H_1 \text{ True}] = \frac{\text{# Tests Rejected}}{\text{# Simulations}}
\]

We're investigating the relationship between power and n, $\beta_1$ and $\sigma$.

## Methods

```{r}
birthday = 19870725
set.seed(birthday)
```


```{r}
# power function taking n, sigma and num_sims as parameters and returning a data frame
beta_1 = seq(-2, 2, 0.1)
beta_0 = 0
alpha = 0.05
  
power_hat = rep(0, length(beta_1)) 
power_data = data.frame(beta_1, power_hat)

power_function= function(n, sigma, num_sims){
  


  x_values = seq(0, 5, length = n)
  y_values = rep(0, n)
  sim_data = data.frame(x_values, y_values)

  j = 1
  for (b in beta_1){
    h0 = 0
    for (i in 1:num_sims){
      eps = rnorm(n, mean = 0, sd = sigma)
      sim_data$y_values = beta_0 + b * x_values + eps
      fit = lm(y_values ~ x_values, sim_data)
      p_value  = summary(fit)$coefficients[2, "Pr(>|t|)"]
      if (p_value < alpha){
        h0 = h0 + 1
      }
    }  
    power_data$power_hat[j] =  h0 / num_sims
    j = j + 1
  }
  return(power_data)
}
```

## Results

- $\sigma = 1$
```{r}
power_sig1_n10 = power_function(n = 10, sigma = 1, num_sims = 1000)
power_sig1_n20 = power_function(n = 20, sigma = 1, num_sims = 1000)
power_sig1_n30 = power_function(n = 30, sigma = 1, num_sims = 1000)


plot(power_hat ~ beta_1, data = power_sig1_n10, xlab="beta", ylab="power", main="Power vs. Beta", type = "l", lty = 2, lwd = 2, col="dodgerblue")
lines(power_sig1_n20$beta_1, power_sig1_n20$power_hat, lty = 2, lwd = 2, col = "blue")
lines(power_sig1_n30$beta_1, power_sig1_n30$power_hat, lty = 2, lwd = 2, col = "darkblue")
legend("bottomright", c("n = 10", "n = 20", "n = 30"), lty = 2, lwd = 2,
       col = c("dodgerblue","blue", "darkblue"))

```

- $\sigma = 2$

```{r}
power_sig2_n10 = power_function(n = 10, sigma = 2, num_sims = 1000)
power_sig2_n20 = power_function(n = 20, sigma = 2, num_sims = 1000)
power_sig2_n30 = power_function(n = 30, sigma = 2, num_sims = 1000)

plot(power_hat ~ beta_1, data = power_sig2_n10, xlab="beta", ylab="power", main="Power vs. Beta", type = "l", lty = 2, lwd = 2, col="dodgerblue")
lines(power_sig2_n20$beta_1, power_sig2_n20$power_hat, lty = 2, lwd = 2, col = "blue")
lines(power_sig2_n30$beta_1, power_sig2_n30$power_hat, lty = 2, lwd = 2, col = "darkblue")
legend("bottomright", c("n = 10", "n = 20", "n = 30"), lty = 2, lwd = 2,
       col = c("dodgerblue","blue", "darkblue"))

```


- $\sigma = 4$
```{r}
power_sig4_n10 = power_function(n = 10, sigma = 4, num_sims = 1000)
power_sig4_n20 = power_function(n = 20, sigma = 4, num_sims = 1000)
power_sig4_n30 = power_function(n = 30, sigma = 4, num_sims = 1000)


plot(power_hat ~ beta_1, data = power_sig4_n10, xlab="beta", ylab="power", main="Power vs. Beta", type = "l", lty = 2, lwd = 2, col="dodgerblue")
lines(power_sig4_n20$beta_1, power_sig4_n20$power_hat, lty = 2, lwd = 2, col = "blue")
lines(power_sig4_n30$beta_1, power_sig4_n30$power_hat, lty = 2, lwd = 2, col = "darkblue")
legend("bottomright", c("n = 10", "n = 20", "n = 30"), lty = 2, lwd = 2,
       col = c("dodgerblue","blue", "darkblue"))

```


## Discussion

- How do n, $\beta_1$, and $\sigma$ affect power?

When n increases, power curves become narrower.
When $\sigma$ (noise) increases, power curves tend to be lumpier and more spread out.
The maximum of power is 1. For negative $\beta_1$s, when $\beta_1$ increases, power decreases from the maximum till it reaches the minimum ($\beta_1$ = 0); For positive $\beta_1$s, when $\beta_1$ increases, power increases till it reaches to the maximum again.  

- Are 1000 simulations sufficient?

Power is the number of times we reject the null hypothesis / number of simulations (1000) and we want it closer to 1 in an ideal world. The more simulations we run, the closer our estimations of power get to their true values. We could run it 10000 times, but 1000 is good enough considering $\alpha$ = 0.05, we only need to be 95% confident for our estimations. And the plot shows that difference between 1000 times of simulation and 2000 times is relatively small ($\sigma$ = 1).

```{r}
power_sig1_n10_100 = power_function(n = 10, sigma = 1, num_sims = 100)
power_sig1_n10_2000 = power_function(n = 10, sigma = 1, num_sims = 2000)

plot(power_hat ~ beta_1, data = power_sig1_n10, xlab="beta", ylab="power", main="Power vs. Beta", type = "l", lty = 2, lwd = 2, col="dodgerblue")
lines(power_sig1_n10_100$beta_1, power_sig1_n10_100$power_hat, lty = 2, lwd = 2, col = "red")
lines(power_sig1_n10_2000$beta_1, power_sig1_n10_2000$power_hat, lty = 2, lwd = 2, col = "blue")
legend("bottomright", c("1000 times", "100 times", "2000 times"), lty = 2, lwd = 2,
       col = c("dodgerblue","red", "blue"))

```



