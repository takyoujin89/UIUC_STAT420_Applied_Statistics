---
title: "Week 3 - Homework"
author: "STAT 420, Summer 2018, Bryna Zhao"
date: '06/02/2018'
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---

***

## Exercise 1 (Using `lm` for Inference)

For this exercise we will use the `cats` dataset from the `MASS` package. You should use `?cats` to learn about the background of this dataset.

**(a)** Fit the following simple linear regression model in `R`. Use heart weight as the response and body weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `cat_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
library(MASS)
cat_model = lm(Hwt ~ Bwt, data = cats)
summary(cat_model)$coefficients
```
**a1. The null and alternative hypotheses**
\[
H_0: \beta_1 = 0 \quad \text{vs} \quad H_1: \beta_1 \neq 0
\]

**a2. The value of the test statistic**

**The t value for testing our null and alternative hypotheses is 16.11939.**
```{r}
summary(cat_model)$coefficients[2, 3]
```

**a3. The p-value of the test**

**The p-value of the test is 6.969045e-34.**
```{r}
summary(cat_model)$coefficients[2, 4]
```

**a4. A statistical decision at $\alpha = 0.05$**
**a5. A conclusion in the context of the problem**

**This p-value is smaller than the alpha, we would reject the null hypothesis, and we could say there is a significant linear relationship between cats' body weight and heart weight.**
```{r}
summary(cat_model)$coefficients[2, 4] < 0.05
```


**(b)** Calculate a 90% confidence interval for $\beta_1$. Give an interpretation of the interval in the context of the problem.

**The confidence interval for $\beta_1$ is 3.619716 to 4.4484094. It means that we are 90% confident that for an increase in cat body weight of one kg, the average increase in heart weight is between 3.619716 g and 4.4484094 g.**
```{r}
confint(cat_model, parm = "Bwt", level = 0.9)
#confint(cat_model, level = 0.9)
```


**(c)** Calculate a 99% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.

**The confidence interval for $\beta_0$ is -2.164125 to 1.450800. It means that we are 99% confident that the average heart weight of a cat weighting 0 kg is between -2.164125 g to 1.450800 g, but it's only an estimate and we don't really believe that, since we are actually certian that a heart weight would be non-negative.**

```{r}
confint(cat_model, parm = "(Intercept)", level = 0.99)
#confint(cat_model, level = 0.99)
```

**(d)** Use a 99% confidence interval to estimate the mean heart weight for body weights of 2.1 and 2.8 kilograms. Which of the two intervals is wider? Why?

**The confidence interval for the mean heart weight of a cat weighting 2.1 kg is 7.599225 g to 8.630513 g, and for a cat weighting 2.8 kg is 10.618796 g to 11.258630 g. The confidence interval for mean heart weight of a 2.1 kg cat is wider because 2.7 is further away from the mean body weight which is 2.723611 kg (higher standard error as well).**
```{r}
new_bwt = data.frame(Bwt = c(2.1, 2.8))
# confidence interval for mean response
ci_band = predict(cat_model, newdata = new_bwt,
        interval = c("confidence"), level = 0.99)
ci_band
width21 = ci_band[1, 3] - ci_band[1, 2]
width28 = ci_band[2, 3] - ci_band[2, 2]
width21 > width28
mean(cats$Bwt)
mean(cats$Bwt) - 2.1 > mean(cats$Bwt) - 2.8

```


**(e)** Use a 99% prediction interval to predict the heart weight for body weights of 2.8 and 4.2 kilograms.

**The prediction interval for the heart weight of a cat weighting 2.8 kg is 7.133247 g to 14.74418 g, and for a cat weighting 4.2 kg is 12.660883 g to 20.51192 g.**

```{r}
new_bwt = data.frame(Bwt = c(2.8, 4.2))
# prediction interval for new observations
pi_band = predict(cat_model, newdata = new_bwt,
        interval = c("prediction"), level = 0.99)
pi_band

```


**(f)** Create a scatterplot of the data. Add the regression line, 90% confidence bands, and 90% prediction bands.

```{r}
grid = seq(min(cats$Bwt), max(cats$Bwt), by = 0.01)
hwt_ci_band = predict(cat_model, newdata = data.frame(Bwt = grid),
        interval = c("confidence"), level = 0.9)
hwt_pi_band = predict(cat_model, newdata = data.frame(Bwt = grid),
        interval = c("prediction"), level = 0.9)
plot(Hwt ~ Bwt, data = cats,
     xlab = "Cat Body Weight in KG",
     ylab = "Cat Heart Weight in G",
     main = "Cat Body Weights vs. Heart Weights",
     pch = 20,
     cex = 2,
     col = "grey",
     ylim = c(min(hwt_pi_band), max(hwt_pi_band)))
abline(cat_model, lwd = 5, col = "darkorange")
lines(grid, hwt_ci_band[,"lwr"], col = "dodgerblue", lwd = 3, lty = 2)
lines(grid, hwt_ci_band[,"upr"], col = "dodgerblue", lwd = 3, lty = 2)
lines(grid, hwt_pi_band[,"lwr"], col = "dodgerblue", lwd = 3, lty = 3)
lines(grid, hwt_pi_band[,"upr"], col = "dodgerblue", lwd = 3, lty = 3)

legend("bottomright", title = "Regression Line and CI/PI Bands", 
       legend = c("Regression Line", "90% Confidence Bands", "90% Prediction Bands"), 
       lwd = 2, lty = c(1, 2, 3), col = c("darkorange", "dodgerblue", "dodgerblue"))
```


**(g)** Use a $t$ test to test:

- $H_0: \beta_1 = 4$
- $H_1: \beta_1 \neq 4$

Report the following:

- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.


**g1. The value of the test statistic**

**The value of the test statistic is 0.1361084.**

```{r}

# textbook 8.5 t = (beta_1_hat - beta_10) / SE[beta_1_hat]
t = (summary(cat_model)$coefficients[2, 1] - 4 ) / summary(cat_model)$coefficients[2, 2]
t
```

**g2. The p-value of the test**

**The p-value of the test is 0.8919283.**
```{r}
pt(t, df = nrow(cats) - 2, lower.tail = FALSE) * 2
```
**g3. A statistical decision at $\alpha = 0.05$**

**Since the p-value is not smaller than our alpha, we would fail to reject the null hypothesis, which means it's possible that $\beta_1 = 4$.**
```{r}
pt(t, df = nrow(cats) - 2, lower.tail = FALSE) * 2 < 0.05
```


```{r}
# another way to confirm it using build in parameter "offset"
new_cat_model = lm(Hwt ~ Bwt, data = cats, offset = 4.00 * Bwt)
summary(new_cat_model)
summary(new_cat_model)$coefficients[2, 3]
summary(new_cat_model)$coefficients[2, 4]
summary(new_cat_model)$coefficients[2, 4] < 0.05
```

***

## Exercise 2 (More `lm` for Inference)

For this exercise we will use the `Ozone` dataset from the `mlbench` package. You should use `?Ozone` to learn about the background of this dataset. You may need to install the `mlbench` package. If you do so, do not include code to install the package in your `R` Markdown document.

For simplicity, we will re-perform the data cleaning done in the previous homework.

```{r}
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]

```

**(a)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and wind speed as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_wind_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
ozone_wind_model = lm(ozone ~ wind, data = Ozone)
summary(ozone_wind_model)$coefficients
```
**a1. The null and alternative hypotheses**
\[
H_0: \beta_1 = 0 \quad \text{vs} \quad H_1: \beta_1 \neq 0
\]

**a2. The value of the test statistic**

**The t value for testing our null and alternative hypotheses is -0.2189811.**
```{r}
summary(ozone_wind_model)$coefficients[2, 3]
```

**a3. The p-value of the test**

**The p-value of the test is 0.8267954.**
```{r}
summary(ozone_wind_model)$coefficients[2, 4]
```

**a4. A statistical decision at $\alpha = 0.01$**
**a5. A conclusion in the context of the problem**

**This p-value is not smaller than the alpha, we would fail to reject the null hypothesis and we could say there is no significant linear relationship between wind and ozone.**
```{r}
summary(ozone_wind_model)$coefficients[2, 4] < 0.01
```


**(b)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and temperature as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_temp_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
ozone_temp_model = lm(ozone ~ temp, data = Ozone)
summary(ozone_temp_model)$coefficients
```
**b1. The null and alternative hypotheses**
\[
H_0: \beta_1 = 0 \quad \text{vs} \quad H_1: \beta_1 \neq 0
\]

**b2. The value of the test statistic**

**The t value for testing our null and alternative hypotheses is 22.84896.**
```{r}
summary(ozone_temp_model)$coefficients[2, 3]
```

**b3. The p-value of the test**

**The p-value of the test is 8.153764e-71.**
```{r}
summary(ozone_temp_model)$coefficients[2, 4]
```

**b4. A statistical decision at $\alpha = 0.01$**
**b5. A conclusion in the context of the problem**

**This p-value is smaller than the alpha, we would reject the null hypothesis and we could say there is a significant linear relationship between temperature and ozone.**
```{r}
summary(ozone_temp_model)$coefficients[2, 4] < 0.01
```


***

## Exercise 3 (Simulating Sampling Distributions)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = -5$
- $\beta_1 = 3.25$
- $\sigma^2 = 16$

We will use samples of size $n = 50$.

**(a)** Simulate this model $2000$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_0$ and $\hat{\beta}_1$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 19870725
set.seed(birthday)
n = 50
x = seq(0, 10, length = n)
# x
```

```{r}
beta_0 = -5
beta_1 = 3.25
sigma = sqrt(16)
num_samples = 2000

Sxx = sum((x - mean(x)) ^ 2)
var_beta_1_hat = sigma ^ 2 / Sxx
var_beta_0_hat = sigma ^ 2 * (1 / n + mean(x) ^ 2  / Sxx)

beta_0_hats = rep(0, num_samples)
beta_1_hats = rep(0, num_samples)

for (i in 1:num_samples){
  epsilon = rnorm(n = 50, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  sim_model = lm(y ~ x)
  beta_0_hats[i] = coef(sim_model)[1]
  beta_1_hats[i] = coef(sim_model)[2]
}
# mean(beta_0_hats)
# mean(beta_1_hats)
```

**(b)** Create a table that summarizes the results of the simulations. The table should have two columns, one for $\hat{\beta}_0$ and one for $\hat{\beta}_1$. The table should have four rows:

- A row for the true expected value given the known values of $x$
- A row for the mean of the simulated values
- A row for the true standard deviation given the known values of $x$
- A row for the standard deviation of the simulated values

```{r}
sim_table = data.frame("Compare" = c("True values", "Empirical mean", "True sd", "Empirical sd"), 
                       "beta_0" = c(beta_0, (mean(beta_0_hats)), sqrt(var_beta_0_hat), sd(beta_0_hats)),
                       "beta_1" = c(beta_1, (mean(beta_1_hats)), sqrt(var_beta_1_hat), sd(beta_1_hats)))
library(knitr)
kable(sim_table)
```

**(c)** Plot two histograms side-by-side:

- A histogram of your simulated values for $\hat{\beta}_0$. Add the normal curve for the true sampling distribution of $\hat{\beta}_0$.
- A histogram of your simulated values for $\hat{\beta}_1$. Add the normal curve for the true sampling distribution of $\hat{\beta}_1$.

```{r}
par(mfrow = c(1,2))
hist(beta_0_hats, prob = TRUE, breaks = 20,
     xlab = expression(hat(beta)[0]), main = "", border = "dodgerblue")
curve(dnorm(x, mean = beta_0, sd = sqrt(var_beta_0_hat)), col = "darkorange", add = TRUE, lwd = 3)

hist(beta_1_hats, prob = TRUE, breaks = 20,
     xlab = expression(hat(beta)[1]), main = "", border = "dodgerblue")
curve(dnorm(x, mean = beta_1, sd = sqrt(var_beta_1_hat)), col = "darkorange", add = TRUE, lwd = 3)
```


***

## Exercise 4 (Simulating Confidence Intervals)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 5$
- $\beta_1 = 2$
- $\sigma^2 = 9$

We will use samples of size $n = 25$.

Our goal here is to use simulation to verify that the confidence intervals really do have their stated confidence level. Do **not** use the `confint()` function for this entire exercise.

**(a)** Simulate this model $2500$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_1$ and $s_e$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 19870725
set.seed(birthday)
n = 25
x = seq(0, 2.5, length = n)
```

```{r}
beta_0 = 5
beta_1 = 2
sigma = sqrt(9)
num_samples = 2500

Sxx = sum((x - mean(x)) ^ 2)
var_beta_1_hat = sigma ^ 2 / Sxx

beta_1_hats = rep(0, num_samples)
beta_1_hat_se = rep(0, num_samples)

for (i in 1:num_samples){
  epsilon = rnorm(n = 25, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  sim_model = lm(y ~ x)
  beta_1_hats[i] = coef(sim_model)[2]
  beta_1_hat_se[i] = summary(sim_model)$sigma / sqrt(Sxx)
}
# mean(beta_1_hats)
# mean(beta_1_hat_se)
```

**(b)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 95% confidence interval. Store the lower limits in a vector `lower_95` and the upper limits in a vector `upper_95`. Some hints:

- You will need to use `qt()` to calculate the critical value, which will be the same for each interval.
- Remember that `x` is fixed, so $S_{xx}$ will be the same for each interval.
- You could, but do not need to write a `for` loop. Remember vectorized operations.

```{r}
alpha = 0.95
p =  1 - (1 - alpha) / 2
crit = qt(p, df = n - 2)
lower_95 = beta_1_hats - crit * beta_1_hat_se
upper_95 = beta_1_hats + crit * beta_1_hat_se
#mean(lower_95)
#mean(upper_95)

```

**(c)** What proportion of these intervals contains the true value of $\beta_1$?

**95.6% of these intervals contains the true value of $\beta_1$.**
```{r}
# sum(lower_95 <= beta_1 & beta_1 <= upper_95) / length(lower_95)
mean(lower_95 <= beta_1 & beta_1 <= upper_95)
```


**(d)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.05$?

**66.28% of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.05$.**
```{r}

# 1 - sum(lower_95 <= 0  & 0  <= upper_95) / length(lower_95) 
1 - mean(lower_95 <= 0 & 0 <= upper_95)
```

**(e)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 99% confidence interval. Store the lower limits in a vector `lower_99` and the upper limits in a vector `upper_99`.


```{r}
alpha = 0.99
p =  1 - (1 - alpha) / 2
crit = qt(p, df = n - 2)
lower_99 = beta_1_hats - crit * beta_1_hat_se
upper_99 = beta_1_hats + crit * beta_1_hat_se
```

**(f)** What proportion of these intervals contains the true value of $\beta_1$?


**99.28% of these intervals contains the true value of $\beta_1$.**

```{r}
mean(lower_99 <= beta_1 & beta_1 <= upper_99 )
```


**(g)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.01$?

**39.2% of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.01$.**

```{r}
1 - mean(lower_99 <= 0 & 0 <= upper_99 ) 
```


***

## Exercise 5 (Prediction Intervals "without" `predict`)

Write a function named `calc_pred_int` that performs calculates prediction intervals:

$$
\hat{y}(x) \pm t_{\alpha/2, n - 2} \cdot s_e\sqrt{1 + \frac{1}{n}+\frac{(x-\bar{x})^2}{S_{xx}}}.
$$

for the linear model

$$
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i.
$$

**(a)** Write this function. You may use the `predict()` function, but you may **not** supply a value for the `level` argument of `predict()`. (You can certainly use `predict()` any way you would like in order to check your work.)

The function should take three inputs:

- `model`, a model object that is the result of fitting the SLR model with `lm()`
- `newdata`, a data frame with a single observation (row)
    - This data frame will need to have a variable (column) with the same name as the data used to fit `model`.
- `level`, the level (0.90, 0.95, etc) for the interval with a default value of `0.95`

The function should return a named vector with three elements:

- `estimate`, the midpoint of the interval
- `lower`, the lower bound of the interval
- `upper`, the upper bound of the interval


```{r}

calc_pred_int = function(model, newdata, level = 0.95){
  # extract x, y and sample size
  n = length(((model$model)[2])[,1])
  x = ((model$model)[2])[,1]
  y = ((model$model)[1])[,1]
  # fitted values of y
  y_fit = model$fitted.values
  
  # coefficients
  beta_0 = model$coefficients[1]
  beta_1 = model$coefficients[2]

  x_pred = newdata[1,]
  y_pred = beta_0 + beta_1 * x_pred
  
  
  sse = sum((y - y_fit) ^ 2)
  s_e = sqrt(sse / (n-2)) 
  Sxx = sum((x - mean(x)) ^ 2)
  
  p =  1 - (1 - level) / 2
  # critical value
  crit = qt(p, n - 2)
  
  lower = y_pred - crit * s_e * sqrt(1 + (1 / n) + (x_pred - mean(x)) ^ 2 / Sxx)
  upper = y_pred + crit * s_e * sqrt(1 + (1 / n) + (x_pred - mean(x)) ^ 2 / Sxx)
  estimate = (lower + upper) / 2
  return(c(estimate, lower, upper))
}
```


**(b)** After writing the function, run this code:

```{r}
newcat_1 = data.frame(Bwt = 4.0)
calc_pred_int(cat_model, newcat_1)
# predict(cat_model, newdata = newcat_1, interval = c("prediction"), level = 0.95)
```

**(c)** After writing the function, run this code:

```{r}

newcat_2 = data.frame(Bwt = 3.3)
calc_pred_int(cat_model, newcat_2, level = 0.99)
# predict(cat_model, newdata = newcat_2, interval = c("prediction"), level = 0.99)
```


